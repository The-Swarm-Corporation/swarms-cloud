envs:
  MODEL_NAME: cogvlm-chat-17b
  HF_HUB_ENABLE_HF_TRANSFER: True



# # # Advanced Kubernetes configurations (optional).
# kubernetes:
#   # The networking mode for accessing SSH jump pod (optional).
#   #
#   # This must be either: 'nodeport' or 'portforward'. If not specified,
#   # defaults to 'portforward'.

#   #
#   # nodeport: Exposes the jump pod SSH service on a static port number on each
#   # Node, allowing external access to using <NodeIP>:<NodePort>. Using this
#   # mode requires opening multiple ports on nodes in the Kubernetes cluster.
#   #
#   # portforward: Uses `kubectl port-forward` to create a tunnel and directly
#   # access the jump pod SSH service in the Kubernetes cluster. Does not
#   # require opening ports the cluster nodes and is more secure. 'portforward'
#   # is used as default if 'networking' is not specified.
#   networking: portforward

#   # The mode to use for opening ports on Kubernetes
#   #
#   # This must be either: 'ingress' or 'loadbalancer'. If not specified,
#   # defaults to 'loadbalancer'.
#   #
#   # loadbalancer: Creates services of type `LoadBalancer` to expose ports.
#   # See https://skypilot.readthedocs.io/en/latest/reference/kubernetes/kubernetes-setup.html#loadbalancer-service.
#   # This mode is supported out of the box on most cloud managed Kubernetes
#   # environments (e.g., GKE, EKS).
#   #
#   # ingress: Creates an ingress and a ClusterIP service for each port opened.
#   # Requires an Nginx ingress controller to be configured on the Kubernetes cluster.
#   # Refer to https://skypilot.readthedocs.io/en/latest/reference/kubernetes/kubernetes-setup.html#nginx-ingress
#   # for details on deploying the NGINX ingress controller.
#   ports: loadbalancer

#   # Attach custom metadata to Kubernetes objects created by SkyPilot
#   #
#   # Uses the same schema as Kubernetes metadata object: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.26/#objectmeta-v1-meta
#   #
#   # Since metadata is applied to all all objects created by SkyPilot,
#   # specifying 'name' and 'namespace' fields here is not allowed.
#   # custom_metadata:
#   #   labels:
#   #     mylabel: myvalue
#   #   annotations:
#   #     myannotation: myvalue

#   # Additional fields to override the pod fields used by SkyPilot (optional)
#   #
#   # Any key:value pairs added here would get added to the pod spec used to
#   # create SkyPilot pods. The schema follows the same schema for a Pod object
#   # in the Kubernetes API:
#   # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.26/#pod-v1-core
#   #
#   # # Some example use cases are shown below. All fields are optional.
#   # pod_config:
#   #   spec:
#   #     runtimeClassName: nvidia    # Custom runtimeClassName for GPU pods.
#   #     containers:
#   #       - env:                # Custom environment variables for the pod, e.g., for proxy
#   #         - name: HTTP_PROXY
#   #           value: http://proxy-host:3128
#   #         volumeMounts:       # Custom volume mounts for the pod
#   #           - mountPath: /foo
#   #             name: swarms
#   #             readOnly: true
#   #     volumes:
#   #       - name: swarms
#   #         hostPath:
#   #           path: /tmp
#   #           type: Directory
#   #       - name: swarms          # Use this to modify the /dev/shm volume mounted by SkyPilot
#   #         emptyDir:
#   #           medium: Memory
#   #           sizeLimit: 3Gi    # Set a size limit for the /dev/shm volume


# Fields below describe each replica.
resources:
  accelerators: {
  #  K80:1,
  #  K80:8,
  #  K80:16,
  #  L4:1,
  #  L4:4,
  #  L4:8,
  #  A10G:1,
  #  A10G:4,
  #  A10G:8,
  #  A100:4,
  #  A100:8,
  #  A100-80GB:2,
  #  A100-80GB:4,
  #  A100-80GB:8,
  #  H100:8,
  #  M60:1,
  #  M60:2,
  #  M60:4,
   T4:1,
  #  T4:4,
  #  T4:8,
  #  V100:1,
  #  V100:4,
  #  V100:8,
  #  V100-32GB:8,
  #  Gaudi HL-205:8,
  #  Radeon Pro V520:1,
  #  T4g:1,
  #  T4g:2
  }

  # cpus: +
  # memory: 128+
  # use_spot: True
  # disk_size: 512  # Ensure model checkpoints (~246GB) can fit.
  # disk_tier: best
  # region: us-east-2 
  ports: 8000  # Expose to internet traffic.
  # spot_recovery: none

workdir: .

setup: |
  git clone https://github.com/ZackBradshaw/swarms-cloud/tree/main && \
  cd swarms-cloud/servers/cogvlm && \
  curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add - && \
  distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \
  curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list && \
  sudo apt-get update && \
  sudo apt-get install -y nvidia-container-runtime && \
  sudo nvidia-container-runtime configure --runtime=docker && \
  sudo systemctl restart docker && \
  sudo docker build -t cogvlm_api:latest .
run: |
  sudo docker run --gpus all --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=all -p 8000:8000 cogvlm_api:latest
  
# service.yaml
service:
  # An actual request for readiness probe.
  readiness_probe:
    path: /v1/chat/completions
    post_data:
      model: $MODEL_NAME
      messages:
        - role: user
          content: Hello! What is your name?
      max_tokens: 1
  readiness_probe: /health
  replica_policy:
    min_replicas: 0
    max_replicas: 2
    target_qps_per_replica: 2.5
    upscale_delay_seconds: 300
    downscale_delay_seconds: 1200
